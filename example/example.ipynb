{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-knock",
   "metadata": {},
   "source": [
    "# Example of running PhaseLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-instrumentation",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TomSHudson/PhaseLink/blob/master/example/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "Note that you need to change the run instance to GPU if using colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify if running in google colab:\n",
    "use_google_colab = True\n",
    "\n",
    "# Install/add neccessary paths if using colab:\n",
    "if use_google_colab:\n",
    "    !pip install obspy\n",
    "    # Install nvidia-apex:\n",
    "    !git clone https://github.com/NVIDIA/apex\n",
    "    !pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "religious-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import neccessary modules:\n",
    "import sys, shutil\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import numpy as np \n",
    "import torch\n",
    "import gc \n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "# if not use_google_colab:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# And import PhaseLink:\n",
    "if use_google_colab:\n",
    "  shutil.rmtree('./PhaseLink', ignore_errors=True)\n",
    "  !git clone https://github.com/TomSHudson/PhaseLink.git\n",
    "  sys.path.append('./PhaseLink/')\n",
    "else:\n",
    "  sys.path.append('..')\n",
    "import phaselink_dataset\n",
    "import phaselink_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "several-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy over example files into pwd if using colab:\n",
    "if use_google_colab:\n",
    "  !cp PhaseLink/example/params.json .\n",
    "  !cp PhaseLink/example/station_list.txt .\n",
    "  !cp PhaseLink/example/tt.pg .\n",
    "  !cp PhaseLink/example/tt.sg ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-tender",
   "metadata": {},
   "source": [
    "## 0. Load in param file and key info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "agricultural-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import param json file:\n",
    "params_fname = \"params.json\"\n",
    "with open(params_fname, \"r\") as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "# Get GPU info if using colab:\n",
    "if use_google_colab:\n",
    "     print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "     params['device'] = \"cuda:0\" # Use first GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-element",
   "metadata": {},
   "source": [
    "## 1. Create a synthetic training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "normal-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up...\n",
      "Starting thread 0\n",
      "Starting thread 1\n",
      "Starting thread 2\n",
      "Starting thread 3\n",
      "Starting thread 4\n",
      "Starting thread 5\n",
      "Starting thread 6\n",
      "Starting thread 7\n",
      "Creating the following files for the PhaseLink synthetic training dataset:\n",
      "station_map.pkl\n",
      "sncl_map.pkl\n",
      "shimane_train_X.npy\n",
      "shimane_train_Y.npy\n",
      "P-phases (zeros): 11973180 ( 98.0604422604 %)\n",
      "S-phases (ones): 236820 ( 1.93955773956 %)\n",
      "Saved the synthetic training dataset.\n"
     ]
    }
   ],
   "source": [
    "# Set key parameters from param file:\n",
    "max_picks = params['n_max_picks']\n",
    "t_max = params['t_win']\n",
    "n_threads = params['n_threads']\n",
    "\n",
    "print(\"Starting up...\")\n",
    "# Setup grid:\n",
    "phase_idx = {'P': 0, 'S': 1}\n",
    "lat0, lon0 = phaselink_dataset.get_network_centroid(params)\n",
    "stlo, stla, phasemap, sncl_idx, stations, sncl_map = \\\n",
    "    phaselink_dataset.build_station_map(params, lat0, lon0, phase_idx)\n",
    "x_min = np.min(stlo)\n",
    "x_max = np.max(stlo)\n",
    "y_min = np.min(stla)\n",
    "y_max = np.max(stla)\n",
    "for key in sncl_map:\n",
    "    X0, Y0 = stations[key]\n",
    "    X0 = (X0 - x_min) / (x_max - x_min)\n",
    "    Y0 = (Y0 - y_min) / (y_max - y_min)\n",
    "    stations[key] = (X0, Y0)\n",
    "\n",
    "# Save station maps for detect mode\n",
    "pickle.dump(stations, open(params['station_map_file'], 'wb'))\n",
    "pickle.dump(sncl_map, open(params['sncl_map_file'], 'wb'))\n",
    "\n",
    "# # Pwaves\n",
    "# pTT = tt_interp(params['tt_table']['P'], params['datum'])\n",
    "# print('Read pTT')\n",
    "# print('(dep,dist) = (0,0), (10,0), (0,10), (10,0):')\n",
    "# print('             {:.3f}   {:.3f}   {:.3f}   {:.3f}'.format(\n",
    "# pTT.interp(0,0), pTT.interp(10,0),pTT.interp(0,10),\n",
    "# pTT.interp(10,10)))\n",
    "\n",
    "# #Swaves\n",
    "# sTT = tt_interp(params['tt_table']['S'], params['datum'])\n",
    "# print('Read sTT')\n",
    "# print('(dep,dist) = (0,0), (10,0), (0,10), (10,0):')\n",
    "# print('             {:.3f}   {:.3f}   {:.3f}   {:.3f}'.format(\n",
    "# sTT.interp(0,0), sTT.interp(10,0),sTT.interp(0,10),\n",
    "# sTT.interp(10,10)))\n",
    "\n",
    "# Get travel-time tables for P and S waves:\n",
    "pTT = phaselink_dataset.tt_interp(params['trav_time_p'], params['datum'])\n",
    "sTT = phaselink_dataset.tt_interp(params['trav_time_s'], params['datum'])\n",
    "\n",
    "# Generate synthetic training dataset for given param file:\n",
    "in_q = mp.Queue() ###1000000)\n",
    "out_q = mp.Queue() ###1000000)\n",
    "proc = mp.Process(target=phaselink_dataset.output_thread, args=(out_q, params))\n",
    "proc.start()\n",
    "procs = []\n",
    "for i in range(n_threads):\n",
    "    print(\"Starting thread %d\" % i)\n",
    "    p = mp.Process(target=phaselink_dataset.generate_phases, \\\n",
    "        args=(in_q, out_q, x_min, x_max, y_min, y_max, \\\n",
    "              sncl_idx, stla, stlo, phasemap, pTT, sTT, params))\n",
    "    p.start()\n",
    "    procs.append(p)\n",
    "\n",
    "for i in range(params['n_train_samp']):\n",
    "    in_q.put(i)\n",
    "\n",
    "for i in range(n_threads):\n",
    "    in_q.put(None)\n",
    "#for p in procs:\n",
    "#    p.join()\n",
    "#proc.join()\n",
    "\n",
    "print(\"Creating the following files for the PhaseLink synthetic training dataset:\")\n",
    "print(params['station_map_file'])\n",
    "print(params['sncl_map_file'])\n",
    "print(params['training_dset_X'])\n",
    "print(params['training_dset_Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-basketball",
   "metadata": {},
   "source": [
    "## 2. Train the model using the syntehetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "drawn-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset info:\n",
      "Shape of X: (8140, 1500, 5) Shape of Y (8140, 1500)\n",
      "Begin training process.\n",
      "Epoch 1, 10% \t train_loss: 8.1183e-01 train_acc: 98.24% took: 38.19s\n",
      "Epoch 1, 20% \t train_loss: 4.4219e-01 train_acc: 98.07% took: 35.93s\n",
      "Epoch 1, 31% \t train_loss: 1.7653e-01 train_acc: 98.08% took: 35.90s\n",
      "Epoch 1, 41% \t train_loss: 1.5708e-01 train_acc: 98.06% took: 37.58s\n",
      "Epoch 1, 51% \t train_loss: 1.7691e-01 train_acc: 98.07% took: 36.36s\n",
      "Epoch 1, 62% \t train_loss: 1.9457e-01 train_acc: 98.06% took: 35.61s\n",
      "Epoch 1, 72% \t train_loss: 1.6042e-01 train_acc: 98.08% took: 35.39s\n",
      "Epoch 1, 82% \t train_loss: 1.6453e-01 train_acc: 98.07% took: 35.34s\n",
      "Epoch 1, 93% \t train_loss: 1.4670e-01 train_acc: 98.06% took: 36.86s\n",
      "Precision (Class 0): 0.980%\n",
      "Recall (Class 0): 1.000%\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fdf18133d260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     model_path='./phaselink_model/')\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Begin training process.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/python/github_repositories/PhaseLink_fork/PhaseLink/phaselink_train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, n_epochs, enable_amp)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision (Class 0): {:4.3f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprec_n_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall (Class 0): {:4.3f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreca_0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreca_n_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision (Class 1): {:4.3f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprec_n_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall (Class 1): {:4.3f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreca_1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreca_n_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Get device (cpu vs gpu) specified:\n",
    "device = torch.device(params[\"device\"])\n",
    "if params[\"device\"][0:4] == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    enable_amp = True\n",
    "else:\n",
    "    enable_amp = False\n",
    "if enable_amp:\n",
    "    import apex.amp as amp\n",
    "\n",
    "# Get training info from param file:\n",
    "n_epochs = params[\"n_epochs\"] #100\n",
    "\n",
    "# Load in training dataset:\n",
    "X = np.load(params[\"training_dset_X\"])\n",
    "Y = np.load(params[\"training_dset_Y\"])\n",
    "print(\"Training dataset info:\")\n",
    "print(\"Shape of X:\", X.shape, \"Shape of Y\", Y.shape)\n",
    "dataset = phaselink_train.MyDataset(X, Y, device)\n",
    "\n",
    "# Get dataset info:\n",
    "n_samples = len(dataset)\n",
    "indices = list(range(n_samples))\n",
    "\n",
    "# Set size of training and validation subset:\n",
    "n_test = int(0.1*X.shape[0])\n",
    "validation_idx = np.random.choice(indices, size=n_test, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "\n",
    "# Specify samplers:\n",
    "train_sampler = phaselink_train.SubsetRandomSampler(train_idx)\n",
    "validation_sampler = phaselink_train.SubsetRandomSampler(validation_idx)\n",
    "\n",
    "# Load training data:\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    sampler=validation_sampler\n",
    ")\n",
    "\n",
    "stackedgru = phaselink_train.StackedGRU()\n",
    "stackedgru = stackedgru.to(device)\n",
    "#stackedgru = torch.nn.DataParallel(stackedgru,\n",
    "#    device_ids=['cuda:2', 'cuda:3', 'cuda:4', 'cuda:5'])\n",
    "\n",
    "if enable_amp:\n",
    "    #amp.register_float_function(torch, 'sigmoid')\n",
    "    from apex.optimizers import FusedAdam\n",
    "    optimizer = FusedAdam(stackedgru.parameters())\n",
    "    stackedgru, optimizer = amp.initialize(\n",
    "        stackedgru, optimizer, opt_level='O2')\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(stackedgru.parameters())\n",
    "\n",
    "model = phaselink_train.Model(stackedgru, optimizer, \\\n",
    "    model_path='./phaselink_model/')\n",
    "print(\"Begin training process.\")\n",
    "model.train(train_loader, val_loader, n_epochs, enable_amp=enable_amp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-victor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
